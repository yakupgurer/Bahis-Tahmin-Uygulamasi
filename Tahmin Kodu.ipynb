{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0370eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29,4.64,6.90,2.17,1.51,1.74,1.76,0,1.08,2.49,1.05,1.34,1.68,1.47,2.22,4.33,1.12,1.44,2.34,0,0,0,4.64,1.98,3.11,9.26,1.70,2.35,6.15,1.55,2.95,6.18,1.77,1.76,1.75,19.65,36.00,3.74,7.09,15.40,22.80,20.25,11.90,52,29,17,70,23,5,1506\n",
      "1.96,3.11,3.35,1.63,1.97,1.75,1.76,1.20,1.22,1.55,1.14,1.53,1.31,1.27,2.88,2.97,1.28,1.20,3.46,0,0,0,3.01,1.86,4.31,20.50,2.52,1.92,3.85,2.29,2.36,3.52,1.82,1.71,3.01,14.15,36.00,4.66,4.43,7.29,28.50,14.65,5.64,35,29,35,47,35,17,1506\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "path = \"D:\\chromedriver\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(path)\n",
    "urls = []\n",
    "# \"linkler.txt\" dosyasını okuma\n",
    "sayac=0\n",
    "donusturulecek_liste=[]\n",
    "link_devami=\"basbasa\"\n",
    "with open(\"D:/links2.txt\", \"r\") as dosya:\n",
    "    # Dosyadaki her satırı okuma\n",
    "    for satir in dosya:\n",
    "        # Satır sonundaki newline karakterini ve gereksiz boşlukları temizleme\n",
    "        url = satir.strip()\n",
    "        link_tamami=url+link_devami\n",
    "        # URL'i urls listesine ekleme\n",
    "        urls.append(link_tamami)\n",
    "\n",
    "for x in urls:\n",
    "    try:\n",
    "        driver.get(x)\n",
    "        elements = driver.find_element(\"xpath\", \"//*[@id='middle']/div[4]/div[2]\")\n",
    "        new = elements.text\n",
    "        df = pd.DataFrame(new.split(\"\\n\"))\n",
    "        df2 = df.iloc[10:-11:1]\n",
    "        df2 = df2.drop([11, 12, 14, 15, 17, 18, 20, 21, 23, 24, 26])\n",
    "        df2 = df2.reset_index(drop=True)\n",
    "        df2 = df2.rename(columns={0: \"values\"})\n",
    "        df2 = df2.fillna('0')\n",
    "        df2 = df2.apply(lambda x: x.str.replace(' ', ','))\n",
    "        df2 = df2.apply(lambda x: x.str.replace('-', '0'))\n",
    "\n",
    "        result = ','.join([','.join(row.split(',')) for row in df2.values.flatten()])\n",
    "        result = result.rstrip(\",\")\n",
    "\n",
    "        \n",
    "               \n",
    "        detay_ev = driver.find_element(\"xpath\", \"//*[@id='middle']/div[3]/div[1]/div/div[3]/div/div[1]/table\")\n",
    "        detay2_ev = detay_ev.text\n",
    "\n",
    "        ev_veriler = pd.DataFrame(detay2_ev.split(\"\\n\"))\n",
    "        ev_veriler2 = ev_veriler.iloc[2::3]\n",
    "        ev_veriler2 = ev_veriler2.reset_index(drop=True)\n",
    "        ev_veriler2 = ev_veriler2.rename(columns={0: \"values\"})\n",
    "        ev_veriler2 = ev_veriler2.fillna('0')\n",
    "        ev_veriler2 = ev_veriler2.apply(lambda x: x.str.replace('%', ''))\n",
    "        ev_sonuc = ','.join([','.join(row.split(',')) for row in ev_veriler2.values.flatten()])\n",
    "\n",
    "        detay_dep = driver.find_element(\"xpath\", \"//*[@id='middle']/div[3]/div[1]/div/div[3]/div/div[2]\")\n",
    "        detay2_dep = detay_dep.text\n",
    "\n",
    "        dep_veriler = pd.DataFrame(detay2_dep.split(\"\\n\"))\n",
    "        dep_veriler2 = dep_veriler.iloc[4::3]\n",
    "        dep_veriler2 = dep_veriler2.reset_index(drop=True)\n",
    "        dep_veriler2 = dep_veriler2.rename(columns={0: \"values\"})\n",
    "        dep_veriler2 = dep_veriler2.fillna('0')\n",
    "        dep_veriler2 = dep_veriler2.apply(lambda x: x.str.replace('%', ''))\n",
    "        dep_sonuc = ','.join([','.join(row.split(',')) for row in dep_veriler2.values.flatten()])\n",
    "        \n",
    "        lig = driver.find_element_by_xpath(\"//*[@id='middle']/div[1]/div/header/h3/a/span[3]\")\n",
    "        lig = lig.text\n",
    "\n",
    "        if (lig == \"Türkiye Süper Lig\"):\n",
    "            lig_id = 1500\n",
    "        if (lig == \"Fransa 2.Lig\"):\n",
    "            lig_id = 1501\n",
    "        if (lig == \"Fransa 1.Lig\"):\n",
    "            lig_id = 1502\n",
    "        if (lig == \"Hollanda Eredivisie\"):\n",
    "            lig_id = 1503\n",
    "        if (lig == \"İngiltere Premier Lig\"):\n",
    "            lig_id = 1504\n",
    "        if (lig == \"İngiltere Championship\"):\n",
    "            lig_id = 1505\n",
    "        if (lig == \"İspanya La Liga\"):\n",
    "            lig_id = 1506\n",
    "        if (lig == \"İtalya Serie A\"):\n",
    "            lig_id = 1507\n",
    "        if (lig == \"Almanya Bundesliga I\"):\n",
    "            lig_id = 1508\n",
    "\n",
    "\n",
    "\n",
    "        donusturulecek_liste.append(result+\",\"+ev_sonuc+\",\"+dep_sonuc+\",\" + str(lig_id))\n",
    "        print(result+\",\"+ev_sonuc+\",\"+dep_sonuc+\",\"+ str(lig_id))\n",
    "        sayac=sayac+1\n",
    "    except Exception as e:\n",
    "        print(\"Hata:\", str(e))\n",
    "        continue\n",
    "\n",
    "\n",
    "donusturulecek_liste=pd.DataFrame(donusturulecek_liste)\n",
    "print(sayac)\n",
    "donusturulecek_liste.to_csv(\"D:/YENI_CEKILEN_TAHMINLER.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
